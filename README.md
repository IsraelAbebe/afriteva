# AfriTeVa: Extending “Small Data” Pretraining Approaches to Sequence-to-Sequence Models 

This repo contains the code for the paper [AfriTeVa: Extending “Small Data” Pretraining Approaches to Sequence-to-Sequence Models ](#)
AfriTeVa is a sequence to 

## Languages Covered During Training

Afaan Oromoo(orm), Amharic(amh), Gahuza(gah), Hausa(hau), Igbo(igb), Nigerian Pidgin(pcm), Somali(som), Swahili(swa), Tigrinya(tig), Yoruba(yor)

## Citation
 xxx

